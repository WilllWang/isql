{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import os\n",
    "import types\n",
    "from copy import deepcopy as copy\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from pyglet.window import key as pygkey\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)\n",
    "mpl.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "assert len(logger.handlers) == 1\n",
    "handler = logger.handlers[0]\n",
    "handler.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newton_conf = {'fps': 40}\n",
    "aristotle_conf = {'fps': 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_choice = 'newton'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', '5.1-lander-%s' % conf_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create envs, pilot policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "throttle_mag = 0.75\n",
    "def disc_to_cont(action):\n",
    "  if type(action) == np.ndarray:\n",
    "    return action\n",
    "  # main engine\n",
    "  if action < 3:\n",
    "    m = -throttle_mag\n",
    "  elif action < 6:\n",
    "    m = throttle_mag\n",
    "  else:\n",
    "    raise ValueError\n",
    "  # steering\n",
    "  if action % 3 == 0:\n",
    "    s = -throttle_mag\n",
    "  elif action % 3 == 1:\n",
    "    s = 0\n",
    "  else:\n",
    "    s = throttle_mag\n",
    "  return np.array([m, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_act_dim = 6\n",
    "n_obs_dim = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_ep_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_goals = np.arange(1, 10, 1).astype(int)\n",
    "n_train_tasks = train_goals.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert conf_choice == 'newton'\n",
    "def make_lander_env(goal=None):\n",
    "  env = gym.make('LunarLanderContinuous-v2')\n",
    "  env.unwrapped.goal = goal\n",
    "  env.action_space = spaces.Discrete(n_act_dim)\n",
    "  env.unwrapped._step_orig = env.unwrapped._step\n",
    "  def _step(self, action):\n",
    "    obs, r, done, info = self._step_orig(disc_to_cont(action))\n",
    "    return obs, r, done, info\n",
    "  env.unwrapped._step = types.MethodType(_step, env.unwrapped)\n",
    "  env.unwrapped.fps = newton_conf['fps']\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "    input_placeholder,\n",
    "    output_size,\n",
    "    scope,\n",
    "    n_layers=1,\n",
    "    size=256,\n",
    "    activation=tf.nn.relu,\n",
    "    output_activation=None,\n",
    "    reuse=False\n",
    "  ):\n",
    "  out = input_placeholder\n",
    "  with tf.variable_scope(scope, reuse=reuse):\n",
    "    for _ in range(n_layers):\n",
    "      out = tf.layers.dense(out, size, activation=activation)\n",
    "    out = tf.layers.dense(out, output_size, activation=output_activation)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NNInvDynamicsModel():\n",
    "  \n",
    "  def __init__(self,\n",
    "      n_layers,\n",
    "      size,\n",
    "      activation,\n",
    "      normalization,\n",
    "      batch_size,\n",
    "      iterations,\n",
    "      learning_rate,\n",
    "      sess,\n",
    "      invdyn_scope\n",
    "    ):\n",
    "    self.scope = invdyn_scope\n",
    "    with tf.variable_scope(self.scope, reuse=None):\n",
    "      self.obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_dim])\n",
    "      self.obs_delta_t_ph = tf.placeholder(tf.float32, [None, n_obs_dim])\n",
    "      self.act_t_ph = tf.placeholder(tf.int32, [None])\n",
    "      obs_cat_delta_t = tf.concat([self.obs_t_ph, self.obs_delta_t_ph], axis=1)\n",
    "      self.act_logits = build_mlp(\n",
    "        obs_cat_delta_t, n_act_dim, invdyn_scope, n_layers=n_layers, size=size,\n",
    "        activation=activation\n",
    "      )\n",
    "      self.act_preds = tf.argmax(self.act_logits, axis=1)\n",
    "      self.loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=self.act_t_ph,\n",
    "        logits=self.act_logits,\n",
    "      ))\n",
    "\n",
    "      self.update_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)\n",
    "\n",
    "      tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "    self.sess = sess\n",
    "    self.iterations = iterations\n",
    "    self.batch_size = batch_size\n",
    "    self.normalization = normalization\n",
    "\n",
    "  def fit(self, data):\n",
    "    obs, actions, rewards, next_obs, dones = data\n",
    "    mean_obs, std_obs, mean_deltas, std_deltas = self.normalization\n",
    "    normed_obs = normalize(obs, mean_obs, std_obs)\n",
    "    deltas = next_obs - obs\n",
    "    normed_deltas = normalize(deltas, mean_deltas, std_deltas)\n",
    "\n",
    "    example_idxes = range(len(obs))\n",
    "    def sample_batch(size):\n",
    "      idxes = random.sample(example_idxes, size)\n",
    "      return normed_obs[idxes], actions[idxes], normed_deltas[idxes]\n",
    "\n",
    "    n_iters = self.iterations * len(obs) // self.batch_size\n",
    "    with tf.variable_scope(self.scope, reuse=None):\n",
    "      for i in range(n_iters):\n",
    "        batch_obs_t, batch_act_t, batch_obs_delta = sample_batch(self.batch_size)\n",
    "        feed_dict = {\n",
    "          self.obs_t_ph: batch_obs_t,\n",
    "          self.act_t_ph: batch_act_t,\n",
    "          self.obs_delta_t_ph: batch_obs_delta\n",
    "        }\n",
    "        [loss, _] = self.sess.run([self.loss, self.update_op], feed_dict=feed_dict)\n",
    "        print('%d %d %f' % (i, n_iters, loss))\n",
    "\n",
    "  def predict(self, states, next_states):\n",
    "    mean_obs, std_obs, mean_deltas, std_deltas = self.normalization\n",
    "    normed_states = normalize(states, mean_obs, std_obs)\n",
    "    normed_deltas = normalize(next_states - states, mean_deltas, std_deltas)\n",
    "    with tf.variable_scope(self.scope, reuse=None):\n",
    "      feed_dict = {\n",
    "        self.obs_t_ph: normed_states,\n",
    "        self.obs_delta_t_ph: normed_deltas\n",
    "      }\n",
    "      return self.sess.run(self.act_preds, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data, mean, std, eps=1e-9):\n",
    "  return (data - mean) / (std + eps)\n",
    "\n",
    "def unnormalize(data, mean, std, eps=1e-9):\n",
    "  return data * (std + eps) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "layer_size = 64\n",
    "activation = tf.nn.relu\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'invdyn_normalization.pkl'), 'rb') as f:\n",
    "  normalization = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'invdyn_scope.pkl'), 'rb') as f:\n",
    "  invdyn_scope = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_invdyn_model = NNInvDynamicsModel(\n",
    "  n_layers=n_layers,\n",
    "  size=layer_size,\n",
    "  activation=activation,\n",
    "  normalization=normalization,\n",
    "  batch_size=batch_size,\n",
    "  iterations=iterations,\n",
    "  learning_rate=learning_rate,\n",
    "  sess=sess,\n",
    "  invdyn_scope=invdyn_scope\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "invdyn_path = os.path.join(data_dir, 'invdyn.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_tf_vars(sess, scope, path):\n",
    "  saver = tf.train.Saver([v for v in tf.global_variables() if v.name.startswith(scope + '/')])\n",
    "  saver.restore(sess, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_tf_vars(sess, invdyn_scope, invdyn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert conf_choice == 'aristotle'\n",
    "def make_lander_env(goal=None):\n",
    "  env = gym.make('LunarLanderContinuous-v2')\n",
    "  env.action_space = spaces.Discrete(n_act_dim)\n",
    "  env.unwrapped._step_orig = env.unwrapped._step\n",
    "  def _step(self, action):\n",
    "    if type(action) in [np.int64, int] or len(action) == 1:\n",
    "      if type(action) == np.ndarray:\n",
    "        action = action[0]\n",
    "        \n",
    "      if self.curr_obs is not None:\n",
    "        intended_state = self.sim_step(disc_to_cont(action), **aristotle_conf)[0]\n",
    "        intended_action = true_invdyn_model.predict(\n",
    "          np.array([self.curr_obs]), np.array([intended_state]))[0]\n",
    "      else:\n",
    "        intended_action = action\n",
    "        \n",
    "      obs, r, done, info = self._step_orig(disc_to_cont(intended_action))\n",
    "      info['intended_action'] = intended_action\n",
    "      return obs, r, done, info\n",
    "    else:\n",
    "      return self._step_orig(action)\n",
    "  env.unwrapped._step = types.MethodType(_step, env.unwrapped)\n",
    "  env.unwrapped.fps = newton_conf['fps']\n",
    "  env.unwrapped.goal = goal\n",
    "  return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_ep(policy, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "  global human_agent_action\n",
    "  global human_agent_active\n",
    "  human_agent_action = init_human_action()\n",
    "  human_agent_active = False\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  totalr = 0.\n",
    "  prev_obs = obs\n",
    "  rollout = []\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    if done:\n",
    "      break\n",
    "    action = policy(obs)\n",
    "    obs, r, done, info = env.step(action)\n",
    "    rollout.append((prev_obs, action, r, obs, float(done), task_idx, info.get('intended_action', action)))\n",
    "    prev_obs = obs\n",
    "    if render:\n",
    "      env.render()\n",
    "    totalr += r\n",
    "  return rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_human_action = lambda: [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "human_agent_action = init_human_action()\n",
    "human_agent_active = False\n",
    "\n",
    "LEFT = pygkey.LEFT\n",
    "RIGHT = pygkey.RIGHT\n",
    "UP = pygkey.UP\n",
    "DOWN = pygkey.DOWN\n",
    "\n",
    "def key_press(key, mod):\n",
    "  global human_agent_action\n",
    "  global human_agent_active\n",
    "  a = int(key)\n",
    "  if a == LEFT:\n",
    "    human_agent_action[1] = 0\n",
    "    human_agent_active = True\n",
    "  elif a == RIGHT:\n",
    "    human_agent_action[1] = 2\n",
    "    human_agent_active = True\n",
    "  elif a == UP:\n",
    "    human_agent_action[0] = 1\n",
    "    human_agent_active = True\n",
    "  elif a == DOWN:\n",
    "    human_agent_action[0] = 0\n",
    "    human_agent_active = True\n",
    "\n",
    "def key_release(key, mod):\n",
    "  global human_agent_action\n",
    "  global human_agent_active\n",
    "  a = int(key)\n",
    "  if a == LEFT or a == RIGHT:\n",
    "    human_agent_action[1] = 1\n",
    "    human_agent_active = False\n",
    "  elif a == UP or a == DOWN:\n",
    "    human_agent_action[0] = 0\n",
    "    human_agent_active = False\n",
    "\n",
    "def encode_human_action(action):\n",
    "  return action[0]*3+action[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def human_pilot_policy(obs):\n",
    "  global human_agent_action\n",
    "  return encode_human_action(human_agent_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pilot_id = 'andreea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_demo_eps_per_task = [1 for _ in range(n_train_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = make_lander_env(goal=train_goals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.render()\n",
    "env.unwrapped.viewer.window.on_key_press = key_press\n",
    "env.unwrapped.viewer.window.on_key_release = key_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_rollouts = [[] for _ in range(n_train_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_task_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "while any(len(task_rollouts) < n_demo_eps_of_task for task_rollouts, n_demo_eps_of_task \\\n",
    "          in zip(demo_rollouts, n_demo_eps_per_task)):\n",
    "  if len(demo_rollouts[train_task_idx]) < n_demo_eps_per_task[train_task_idx]:\n",
    "    env.unwrapped.goal = train_goals[train_task_idx]\n",
    "    demo_rollouts[train_task_idx].append(\n",
    "      run_ep(human_pilot_policy, env, render=True, task_idx=train_task_idx))\n",
    "    time.sleep(2)\n",
    "  train_task_idx = (train_task_idx + 1) % n_train_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(len(task_rollouts) for task_rollouts in demo_rollouts), sum(len(task_rollouts) for task_rollouts in demo_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'wb') as f:\n",
    "  pickle.dump(demo_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pilot_ids = [\n",
    "  'spike',\n",
    "  'jet',\n",
    "  'faye',\n",
    "  'vicious',\n",
    "  'ed',\n",
    "  'ein',\n",
    "  'julia',\n",
    "  'punch',\n",
    "  'judy',\n",
    "  'lin',\n",
    "  'grencia',\n",
    "  'laughingbull'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_rollouts = [[] for _ in range(n_train_tasks)]\n",
    "\n",
    "for pilot_id in pilot_ids:\n",
    "  with open(os.path.join(data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    pilot_demo_rollouts = pickle.load(f)\n",
    "    for task_idx, task_rollouts in enumerate(pilot_demo_rollouts):\n",
    "      demo_rollouts[task_idx].extend(task_rollouts)\n",
    "      \n",
    "with open(os.path.join(data_dir, 'human_pilot_policy_demo_rollouts.pkl'), 'wb') as f:\n",
    "  pickle.dump(demo_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newton_data_dir = os.path.join('data', '5.1-lander-newton')\n",
    "aristotle_data_dir = os.path.join('data', '5.1-lander-aristotle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newton_rollouts_of_pilot = {k: [] for k in pilot_ids}\n",
    "aristotle_rollouts_of_pilot = {k: [] for k in pilot_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pilot_id in pilot_ids:\n",
    "  with open(os.path.join(newton_data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    newton_rollouts_of_pilot[pilot_id].extend(sum(pickle.load(f), []))\n",
    "  with open(os.path.join(aristotle_data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    aristotle_rollouts_of_pilot[pilot_id].extend(sum(pickle.load(f), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_of_pilot = {}\n",
    "for pilot_id in pilot_ids:\n",
    "  newton_rollouts = newton_rollouts_of_pilot[pilot_id]\n",
    "  aristotle_rollouts = aristotle_rollouts_of_pilot[pilot_id]\n",
    "  newton_succ = [1 if x[-1][2] == 100 else 0 for x in newton_rollouts]\n",
    "  aristotle_succ = [1 if x[-1][2] == 100 else 0 for x in aristotle_rollouts]\n",
    "  newton_fail = [1 if x[-1][2] == -100 else 0 for x in newton_rollouts]\n",
    "  aristotle_fail = [1 if x[-1][2] == -100 else 0 for x in aristotle_rollouts]\n",
    "  stats_of_pilot[pilot_id] = (\n",
    "    np.mean(newton_succ), np.std(newton_succ) / np.sqrt(len(newton_succ)), len(newton_succ),\n",
    "    np.mean(aristotle_succ), np.std(aristotle_succ) / np.sqrt(len(aristotle_succ)), len(aristotle_succ),\n",
    "    np.mean(newton_fail), np.std(newton_fail) / np.sqrt(len(newton_fail)), len(newton_fail),\n",
    "    np.mean(aristotle_fail), np.std(aristotle_fail) / np.sqrt(len(aristotle_fail)), len(aristotle_fail)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = []\n",
    "for pilot_id in pilot_ids:\n",
    "  s = stats_of_pilot[pilot_id]\n",
    "  ctrl_succ = s[0]\n",
    "  ctrl_fail = s[6]\n",
    "  treat_succ = s[3]\n",
    "  treat_fail = s[9]\n",
    "  out.append([pilot_id, 0, ctrl_succ, ctrl_fail])\n",
    "  out.append([pilot_id, 1, treat_succ, treat_fail])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'lander_hyp_test.csv'), 'w') as f:\n",
    "  f.write('userid,assistance,successrate,crashrate\\n')\n",
    "  f.write('\\n'.join([','.join([str(z) for z in x]) for x in out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solo_pi_succs = []\n",
    "solo_pi_crashes = []\n",
    "comb_succs = []\n",
    "comb_crashes = []\n",
    "for pilot_id in pilot_ids:\n",
    "  s = stats_of_pilot[pilot_id]\n",
    "  ctrl_succ = s[0]\n",
    "  ctrl_fail = s[6]\n",
    "  treat_succ = s[3]\n",
    "  treat_fail = s[9]\n",
    "  solo_pi_succs.append(ctrl_succ)\n",
    "  solo_pi_crashes.append(ctrl_fail)\n",
    "  comb_succs.append(treat_succ)\n",
    "  comb_crashes.append(treat_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(pilot_ids, solo_pi_succs), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(pilot_ids, comb_succs), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Crash Rate')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.title(r'Lunar Lander User Study (%d users)' % len(solo_pi_crashes))\n",
    "plt.scatter(\n",
    "  solo_pi_crashes, solo_pi_succs, label='Unassisted', \n",
    "  color='gray', s=100, marker='o')\n",
    "plt.scatter(\n",
    "  comb_crashes, comb_succs, label='Assisted', \n",
    "  color='orange', s=100, marker='^')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.savefig(os.path.join(data_dir, 'lander-user-study-fig.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Unassisted Success Rate')\n",
    "plt.ylabel('Assisted Success Rate')\n",
    "plt.title('Lunar Lander User Study (%d users)' % len(solo_pi_succs))\n",
    "plt.plot([-0.05, 1.05], [-0.05, 1.05], linestyle='--', color='gray')\n",
    "plt.scatter(solo_pi_succs, comb_succs, color='orange', linewidth=0, s=100)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.savefig(os.path.join(data_dir, 'lander-user-study-succ.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Unassisted Crash Rate')\n",
    "plt.ylabel('Assisted Crash Rate')\n",
    "plt.title('Lunar Lander User Study (%d users)' % len(solo_pi_succs))\n",
    "plt.plot([-0.05, 1.05], [-0.05, 1.05], linestyle='--', color='gray')\n",
    "plt.scatter(solo_pi_crashes, comb_crashes, color='orange', linewidth=0, s=100)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.savefig(os.path.join(data_dir, 'lander-user-study-crash.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_before = {\n",
    "  'ed': [7, 5, 1, 2, 2, 3, 7, 5, 4, 3],\n",
    "  'lin': [3, 1, 1, 1, 7, 1, 7, 2, 2, 2],\n",
    "  'laughingbull': [6, 6, 2, 2, 7, 2, 7, 6, 7, 2],\n",
    "  'ein': [7, 2, 1, 1, 6, 2, 7, 7, 7, 2],\n",
    "  'judy': [7, 4, 1, 1, 7, 2, 7, 6, 7, 7],\n",
    "  'punch': [1, 2, 2, 6, 4, 1, 4, 2, 2, 2],\n",
    "  'spike': [3, 4, 1, 1, 7, 1, 6, 6, 1, 1],\n",
    "  'jet': [2, 2, 1, 2, 6, 2, 6, 5, 5, 4],\n",
    "  'faye': [3, 5, 1, 1, 3, 4, 7, 5, 6, 5],\n",
    "  'julia': [2, 2, 1, 1, 5, 1, 7, 6, 6, 2],\n",
    "  'vicious': [2, 2, 1, 1, 1, 3, 5, 4, 4, 2],\n",
    "  'grencia': [4, 2, 1, 1, 7, 1, 7, 1, 7, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "survey_after = {\n",
    "  'punch': [6, 6, 5, 6, 7, 5, 5, 5, 6, 6],\n",
    "  'judy': [7, 6, 3, 5, 7, 4, 7, 7, 7, 7],\n",
    "  'ein': [7, 6, 3, 3, 1, 3, 7, 7, 7, 5],\n",
    "  'laughingbull': [7, 6, 6, 5, 7, 5, 7, 7, 6, 6],\n",
    "  'lin': [6, 6, 1, 1, 7, 2, 7, 6, 3, 2],\n",
    "  'ed': [7, 7, 3, 3, 6, 5, 7, 6, 5, 5],\n",
    "  'spike': [6, 5, 5, 5, 7, 6, 7, 6, 6, 7],\n",
    "  'jet': [4, 5, 1, 1, 7, 3, 7, 6, 5, 4],\n",
    "  'faye': [5, 6, 2, 2, 5, 4, 7, 6, 6, 6],\n",
    "  'julia': [5, 6, 1, 1, 7, 3, 7, 6, 3, 4],\n",
    "  'vicious': [5, 4, 3, 3, 6, 5, 6, 5, 6, 6],\n",
    "  'grencia': [6, 7, 3, 2, 7, 3, 7, 5, 6, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_qs = [\n",
    "  \"I enjoyed playing the game\",\n",
    "  \"I improved over time\",\n",
    "  \"I didn't crash\",\n",
    "  \"I didn't fly out of bounds\",\n",
    "  \"I didn't run out of time\",\n",
    "  \"I landed between the flags\",\n",
    "  \"I understood how to complete the task\",\n",
    "  \"I intuitively understood the physics of the game\",\n",
    "  \"My actions were carried out\",\n",
    "  \"My intended actions were carried out\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = len(survey_before)\n",
    "n_qs = len(raw_qs)\n",
    "mat_before = np.zeros((n_users, n_qs))\n",
    "for i, (user, resp) in enumerate(survey_before.items()):\n",
    "  mat_before[i, :] = resp\n",
    "mat_after = np.zeros((n_users, n_qs))\n",
    "for i, (user, resp) in enumerate(survey_after.items()):\n",
    "  mat_after[i, :] = resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, q in enumerate(raw_qs):\n",
    "  print('%s &  & %0.2f & %0.2f \\\\\\\\' % (q, mat_before[:, i].mean(), mat_after[:, i].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'survey_hyp_test.csv'), 'w') as f:\n",
    "  f.write('userid,assistance,%s\\n' % ','.join(['Q%d' % i for i in range(len(raw_qs))]))\n",
    "  f.write('\\n'.join([','.join([userid, '0', ','.join([str(x) for x in survey_before[userid]])]) + '\\n' + ','.join([userid, '1', ','.join([str(x) for x in survey_after[userid]])]) for userid in pilot_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_decode(x):\n",
    "  l = np.nonzero(x)[0]\n",
    "  assert len(l) == 1\n",
    "  return l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOOP = 1\n",
    "NOOPS = [NOOP]\n",
    "def compute_in_events_for_comb_traj(traj, acts):\n",
    "  ts = [t for t, obs in enumerate(traj[:-1]) if onehot_decode(obs[-6:]) != NOOP]\n",
    "  return list(np.array(ts) / len(traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_pilot_ids = ['spike', 'jet', 'faye', 'julia', 'vicious', 'grencia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_rollouts = []\n",
    "comb_rollouts = []\n",
    "for pilot_id in analysis_pilot_ids:\n",
    "  with open(os.path.join(newton_data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    eval_rollouts.extend([list(zip(*rollout)) for rollout in sum(pickle.load(f), [])])\n",
    "  with open(os.path.join(aristotle_data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    comb_rollouts.extend([list(zip(*rollout)) for rollout in sum(pickle.load(f), [])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_act_changes(seq):\n",
    "  return np.mean([1 if x != y else 0 for x, y in zip(seq[:-1], seq[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_act_durations(actions):\n",
    "  durations = []\n",
    "  last_dur = 1\n",
    "  for prev, nxt in zip(actions[:-1], actions[1:]):\n",
    "    if prev != nxt:\n",
    "      durations.append(last_dur)\n",
    "      last_dur = 1\n",
    "    else:\n",
    "      last_dur += 1\n",
    "  return durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_speeds(states):\n",
    "  return [np.linalg.norm(x[2:4]) for x in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_changes = []\n",
    "rews = []\n",
    "outcomes = []\n",
    "ins = []\n",
    "act_durations = []\n",
    "speeds = []\n",
    "for rollout in eval_rollouts:\n",
    "  n_changes.append(n_act_changes(rollout[1]))\n",
    "  act_durations.append(np.mean(compute_act_durations(rollout[1])))\n",
    "  speeds.append(np.mean(compute_speeds(rollout[0])))\n",
    "  rews.append(sum(rollout[2]))\n",
    "  outcomes.append(rollout[2][-1] if rollout[2][-1] in [-100, 100] else 0)\n",
    "  ts = [t for t, a in enumerate(rollout[1]) if a != NOOP]\n",
    "  ins.extend(list(np.array(ts) / len(rollout[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_n_changes = []\n",
    "comb_rews = []\n",
    "comb_outcomes = []\n",
    "comb_ins = []\n",
    "comb_act_durations = []\n",
    "comb_speeds = []\n",
    "for rollout in comb_rollouts:\n",
    "  comb_n_changes.append(n_act_changes(rollout[-1]))\n",
    "  comb_act_durations.append(np.mean(compute_act_durations(rollout[-1])))\n",
    "  comb_speeds.append(np.mean(compute_speeds(rollout[0])))\n",
    "  comb_rews.append(sum(rollout[2]))\n",
    "  comb_outcomes.append(rollout[2][-1] if rollout[2][-1] in [-100, 100] else 0)\n",
    "  ts = [t for t, a in enumerate(rollout[1]) if a not in NOOPS]\n",
    "  comb_ins.extend(list(np.array(ts) / len(rollout[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcomes = [x if x in [-100, 100] else 0 for x in outcomes]\n",
    "comb_outcomes = [x if x in [-100, 100] else 0 for x in comb_outcomes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Fraction of Actions that Differ from Previous Action')\n",
    "plt.ylabel('Reward')\n",
    "plt.scatter(n_changes, rews, label='Solo Human Pilot', alpha=0.5, color='gray', linewidth=0)\n",
    "plt.scatter(comb_n_changes, comb_rews, label='Human Pilot + Copilot', alpha=0.5, color='orange', linewidth=0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_n_changes = np.array(n_changes + comb_n_changes)\n",
    "all_outcomes = np.array(outcomes + comb_outcomes)\n",
    "n_changes = np.array(n_changes)\n",
    "comb_n_changes = np.array(comb_n_changes)\n",
    "outcomes = np.array(outcomes)\n",
    "comb_outcomes = np.array(comb_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Actions Per Minute (APM)')\n",
    "plt.ylabel('Number of Trajectories')\n",
    "plt.hist(60 / (np.array(act_durations) * 0.2), alpha=0.5, label='Unassisted', color='gray')#, normed=True)\n",
    "plt.hist(60 / (np.array(comb_act_durations) * 0.2), alpha=0.5, label='Assisted', color='orange')#, normed=True)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Lunar Lander User Study')\n",
    "plt.savefig(os.path.join(data_dir, 'lander-apm.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apm = int(60 / (np.mean(act_durations) * 0.2))\n",
    "comb_apm = int(60 / (np.mean(comb_act_durations) * 0.2))\n",
    "apm, comb_apm, comb_apm / apm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(speeds), np.mean(comb_speeds), (1 - np.mean(comb_speeds) / np.mean(speeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solo_outcomes = []\n",
    "solo_traj = []\n",
    "assisted_outcomes = []\n",
    "assisted_traj = []\n",
    "for pilot_id in pilot_ids:\n",
    "  with open(os.path.join(newton_data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    eval_rollouts = [list(zip(*rollout)) for rollout in sum(pickle.load(f), [])]\n",
    "  with open(os.path.join(aristotle_data_dir, '%s_pilot_policy_demo_rollouts.pkl' % pilot_id), 'rb') as f:\n",
    "    comb_rollouts = [list(zip(*rollout)) for rollout in sum(pickle.load(f), [])]\n",
    "  solo_outcomes.extend([rollout[2][-1] if rollout[2][-1] in [-100, 100] else 0 for rollout in eval_rollouts])\n",
    "  solo_traj.extend([rollout[0] for rollout in eval_rollouts])\n",
    "  assisted_outcomes.extend([rollout[2][-1] if rollout[2][-1] in [-100, 100] else 0 for rollout in comb_rollouts])\n",
    "  assisted_traj.extend([rollout[0] for rollout in comb_rollouts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goals = [round(float(x), 1) for x in np.arange(-0.8, 1, 0.2)]\n",
    "SUCCESS = 100\n",
    "CRASH = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_trajectories(outcomes, trajectories, title, file_name=None, G=0, show_goal=True):\n",
    "  plt.title(title)\n",
    "\n",
    "  for outcome, trajectory in zip(outcomes, trajectories):\n",
    "    x, y, vx, vy, a, av, lc, rc, g = list(zip(*trajectory[::5]))[:9]\n",
    "    if g[0] != G:\n",
    "      continue\n",
    "    if outcome == SUCCESS:\n",
    "      cmap = mpl.cm.YlGn\n",
    "    elif outcome == CRASH:\n",
    "      cmap = mpl.cm.YlOrRd\n",
    "    else:\n",
    "      cmap = mpl.cm.gray\n",
    "    plt.scatter(x, y, c=range(len(x)), cmap=cmap, alpha=0.75, linewidth=0)\n",
    "    if show_goal:\n",
    "      plt.scatter([g[0]], [0], marker='*', color='yellow', edgecolor='black', linewidth=1, s=300, alpha=0.5)\n",
    "    \n",
    "  plt.xlim([-1, 1])\n",
    "  plt.ylim([-0.1, 1.1])\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.axis('off')\n",
    "  if file_name is not None:\n",
    "    plt.savefig(os.path.join(data_dir, file_name), bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories(solo_outcomes, solo_traj, 'Unassisted', 'lander-unassisted-traj.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajectories(assisted_outcomes, assisted_traj, 'Assisted', 'lander-assisted-traj.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
