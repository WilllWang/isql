{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pickle\n",
    "import os\n",
    "import types\n",
    "import random\n",
    "import uuid\n",
    "import math\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.envs.classic_control import rendering\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rc('savefig', dpi=300)\n",
    "mpl.rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join('data', '3.0-continuous-ime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create envs, pilot policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train_tasks = 49\n",
    "n_act_dim = 4\n",
    "n_obs_dim = 4\n",
    "gamma = 0.99\n",
    "max_ep_len = 200\n",
    "accel = 0.01\n",
    "goal_dist_thresh = 2*accel\n",
    "succ_rew_bonus = 1\n",
    "crash_rew_penalty = -1\n",
    "max_speed = 10*accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_succ = lambda r: r[-1][2] > succ_rew_bonus / 2\n",
    "is_crash = lambda r: r[-1][2] < crash_rew_penalty / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_goals = np.random.random((n_train_tasks, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_goals[:, 0], train_goals[:, 1], linewidth=0, color='gray', s=100, marker='*')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'train_goals.pkl'), 'wb') as f:\n",
    "  pickle.dump(train_goals, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'train_goals.pkl'), 'rb') as f:\n",
    "  train_goals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_reward_func(goal):\n",
    "\n",
    "  def reward_shaping(obs):\n",
    "    return -np.linalg.norm((obs[:2] - goal))\n",
    "\n",
    "  def reward_func(prev_obs, action, obs):\n",
    "    pos = obs[:2]\n",
    "    if (pos < 0).any() or (pos >= 1).any():\n",
    "      r = crash_rew_penalty\n",
    "    elif (np.abs(pos - goal) <= goal_dist_thresh).all():\n",
    "      r = succ_rew_bonus\n",
    "    else:\n",
    "      r = gamma * reward_shaping(obs) - reward_shaping(prev_obs)\n",
    "    return r\n",
    "  \n",
    "  return reward_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PointMassNav(gym.Env):\n",
    "  metadata = {\n",
    "    'render.modes': ['human']\n",
    "  }\n",
    "  \n",
    "  def __init__(\n",
    "      self, \n",
    "      using_inertia=True,\n",
    "      max_ep_len=max_ep_len, \n",
    "      reward_func=None,\n",
    "      goal=None,\n",
    "      rand_goal=False,\n",
    "      expose_goal=False\n",
    "    ):\n",
    "    \n",
    "    self.expose_goal = expose_goal\n",
    "    if self.expose_goal:\n",
    "      lows = np.ones(n_obs_dim + 2) * -1\n",
    "      highs = np.ones(n_obs_dim + 2) * 2\n",
    "    else:\n",
    "      lows = np.ones(n_obs_dim) * -1\n",
    "      highs = np.ones(n_obs_dim) * 2\n",
    "      \n",
    "    self.observation_space = spaces.Box(lows, highs)\n",
    "    self.action_space = spaces.Discrete(n_act_dim)\n",
    "    \n",
    "    self.pos = None\n",
    "    self.vel = None\n",
    "    self.curr_step = None\n",
    "    self.viewer = None\n",
    "    self.curr_obs = None\n",
    "    \n",
    "    self.succ_rew_bonus = succ_rew_bonus\n",
    "    self.max_ep_len = max_ep_len\n",
    "    self.reward_func = reward_func\n",
    "    self.using_inertia = using_inertia\n",
    "    self.goal = goal\n",
    "    self.rand_goal = rand_goal\n",
    "    \n",
    "  def _obs_of_pos_vel(self, pos, vel):\n",
    "    if self.expose_goal:\n",
    "      return np.concatenate((pos, vel, self.goal))\n",
    "    else:\n",
    "      return np.concatenate((pos, vel))\n",
    "    \n",
    "  def _obs(self):\n",
    "    self.curr_obs = self._obs_of_pos_vel(self.pos, self.vel)\n",
    "    return self.curr_obs\n",
    "  \n",
    "  def _next_pos_vel(self, pos, vel, action):\n",
    "    next_pos = copy(pos)\n",
    "    if self.using_inertia:\n",
    "      next_vel = copy(vel)\n",
    "    else:\n",
    "      next_vel = np.zeros(2)\n",
    "      \n",
    "    if action == 0: # left\n",
    "      next_vel[1] -= accel\n",
    "    elif action == 1: # right\n",
    "      next_vel[1] += accel\n",
    "    elif action == 2: # up\n",
    "      next_vel[0] -= accel\n",
    "    elif action == 3: # down\n",
    "      next_vel[0] += accel\n",
    "    else:\n",
    "      raise ValueError('invalid action')\n",
    "      \n",
    "    next_vel = np.maximum(np.minimum(next_vel, max_speed), -max_speed)\n",
    "    next_pos += next_vel\n",
    "    \n",
    "    return next_pos, next_vel\n",
    "\n",
    "  def _step(self, action):  \n",
    "    self.pos, self.vel = self._next_pos_vel(self.pos, self.vel, action)\n",
    "        \n",
    "    self.curr_step += 1\n",
    "    succ = (np.abs(self.pos - self.goal) <= goal_dist_thresh).all()\n",
    "    oob = (self.pos < 0).any() or (self.pos >= 1).any()\n",
    "    oot = self.curr_step >= self.max_ep_len\n",
    "    \n",
    "    obs = self._obs()\n",
    "    r = self.reward_func(self.prev_obs, action, obs)\n",
    "    done = oot or succ or oob\n",
    "    info = {}\n",
    "      \n",
    "    self.prev_obs = obs\n",
    "    \n",
    "    return obs, r, done, info\n",
    "    \n",
    "  def _reset(self):\n",
    "    self.pos = np.random.random(2)\n",
    "    self.vel = np.zeros(2)\n",
    "    \n",
    "    if self.rand_goal:\n",
    "      self.goal = np.random.random(2)\n",
    "      self.reward_func = make_reward_func(self.goal)\n",
    "    self.curr_step = 0\n",
    "    self.prev_obs = self._obs()\n",
    "    return self.prev_obs\n",
    "  \n",
    "  def _render(self, mode='human', close=False):\n",
    "    if close:\n",
    "      if self.viewer is not None:\n",
    "        self.viewer.close()\n",
    "        self.viewer = None\n",
    "      return\n",
    "    \n",
    "    if self.viewer is None:\n",
    "      self.viewer = rendering.SimpleImageViewer()\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    \n",
    "    plt.scatter([self.goal[0]], [self.goal[1]], color='gray', linewidth=0, alpha=0.75, marker='*')\n",
    "    plt.scatter([self.pos[0]], [self.pos[1]], color='orange', linewidth=0, alpha=0.75)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    agg = canvas.switch_backends(FigureCanvas)\n",
    "    agg.draw()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    self.viewer.imshow(np.fromstring(agg.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_reward_funcs = [make_reward_func(goal) for goal in train_goals]\n",
    "train_newton_envs = [PointMassNav(reward_func=r, goal=train_goals[i], using_inertia=True) for i, r in enumerate(train_reward_funcs)]\n",
    "train_aristotle_envs = [PointMassNav(reward_func=r, goal=train_goals[i], using_inertia=False) for i, r in enumerate(train_reward_funcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_ep(policy, env, max_ep_len=max_ep_len, render=False, task_idx=None):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  totalr = 0.\n",
    "  prev_obs = obs\n",
    "  rollout = []\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    if done:\n",
    "      break\n",
    "    action = policy(obs)\n",
    "    obs, r, done, info = env.step(action)\n",
    "    rollout.append((prev_obs, action, r, obs, float(done), task_idx))\n",
    "    prev_obs = obs\n",
    "    if render:\n",
    "      env.render()\n",
    "    totalr += r\n",
    "  return rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_aristotle_pilot_policy(goal, denoise=False):\n",
    "  eps = accel if denoise else 0\n",
    "  gx, gy = goal\n",
    "  def aristotle_pilot_policy(obs):\n",
    "    x, y = obs[:2]\n",
    "    up = gx<x-eps\n",
    "    down = gx>x+eps\n",
    "    left = gy<y-eps\n",
    "    right = gy>y+eps\n",
    "    lr = left or right\n",
    "    ud = up or down\n",
    "    if lr and (not ud or np.random.random() < 0.5):\n",
    "      if left:\n",
    "        return 0\n",
    "      elif right:\n",
    "        return 1\n",
    "    elif ud:\n",
    "      if up:\n",
    "        return 2\n",
    "      elif down:\n",
    "        return 3\n",
    "    return 0\n",
    "  return aristotle_pilot_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aristotle_pilot_policies = [make_aristotle_pilot_policy(goal) for goal in train_goals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sanity-check envs, agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_task_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_ep(aristotle_pilot_policies[train_task_idx], train_aristotle_envs[train_task_idx], render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_aristotle_envs[train_task_idx].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_ep(aristotle_pilot_policies[train_task_idx], train_newton_envs[train_task_idx], render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_newton_envs[train_task_idx].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit internal dynamics model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_train_rollouts_per_env = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_rollouts = [[run_ep(aristotle_pilot_policies[train_task_idx], newton_env, render=False, task_idx=train_task_idx)\n",
    "                  for _ in range(n_train_rollouts_per_env)]\n",
    "                 for train_task_idx, newton_env in enumerate(train_newton_envs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_demo_rollouts.pkl'), 'wb') as f:\n",
    "  pickle.dump(demo_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_demo_rollouts.pkl'), 'rb') as f:\n",
    "  demo_rollouts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp(\n",
    "    input_placeholder,\n",
    "    output_size,\n",
    "    scope,\n",
    "    n_layers=1,\n",
    "    size=256,\n",
    "    activation=tf.nn.relu,\n",
    "    output_activation=None,\n",
    "    reuse=False\n",
    "  ):\n",
    "  out = input_placeholder\n",
    "  with tf.variable_scope(scope, reuse=reuse):\n",
    "    for _ in range(n_layers):\n",
    "      out = tf.layers.dense(out, size, activation=activation)\n",
    "    out = tf.layers.dense(out, output_size, activation=output_activation)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot_encode(i, n):\n",
    "  x = np.zeros(n)\n",
    "  x[i] = 1\n",
    "  return x\n",
    "\n",
    "def onehot_decode(x):\n",
    "  l = np.nonzero(x)[0]\n",
    "  assert len(l) == 1\n",
    "  return l[0]\n",
    "\n",
    "n_obs_feats = n_obs_dim\n",
    "def featurize_obs(s):\n",
    "  return s\n",
    "\n",
    "n_act_feats = 2\n",
    "feats_of_act = np.array([\n",
    "  [0, -1],\n",
    "  [0, 1],\n",
    "  [-1, 0],\n",
    "  [1, 0]\n",
    "], dtype=float) * accel\n",
    "def featurize_act(a):\n",
    "  return feats_of_act[a, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vectorize_rollouts(rollouts):\n",
    "  obs = [[] for _ in range(n_train_tasks)]\n",
    "  actions = [[] for _ in range(n_train_tasks)]\n",
    "  for task_idx, task_rollouts in enumerate(rollouts):\n",
    "    for task_rollout in task_rollouts:\n",
    "      more_obs, more_actions = list(zip(*task_rollout))[:2]\n",
    "      obs[task_idx].extend([featurize_obs(s) for s in more_obs])\n",
    "      actions[task_idx].extend(more_actions)\n",
    "  l = min(len(x) for x in obs)\n",
    "  idxes = [random.sample(list(range(len(x))), l) for x in obs]\n",
    "  f = lambda x: np.array(x[1])[idxes[x[0]]]\n",
    "  obs = np.array(list(map(f, enumerate(obs))))\n",
    "  actions = np.array(list(map(f, enumerate(actions))))\n",
    "  return obs, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo_obs = None\n",
    "demo_actions = None\n",
    "demo_next_obs = None\n",
    "demo_task_idxes = None\n",
    "train_demo_example_idxes = None\n",
    "val_demo_batch = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_demo_rollouts(demo_rollouts):\n",
    "  global demo_obs\n",
    "  global demo_actions\n",
    "  global demo_next_obs\n",
    "  global demo_task_idxes\n",
    "  global train_demo_example_idxes\n",
    "  global val_demo_batch\n",
    "\n",
    "  vectorized_demo_rollouts = vectorize_rollouts(demo_rollouts)\n",
    "  \n",
    "  demo_obs, demo_actions = vectorized_demo_rollouts\n",
    "  demo_example_idxes = list(range(demo_obs.shape[1]))\n",
    "  \n",
    "  random.shuffle(demo_example_idxes)\n",
    "  n_train_demo_examples = int(0.9 * len(demo_example_idxes))\n",
    "  train_demo_example_idxes = demo_example_idxes[:n_train_demo_examples]\n",
    "  val_demo_example_idxes = demo_example_idxes[n_train_demo_examples:]\n",
    "  val_demo_batch = demo_obs[:, val_demo_example_idxes], demo_actions[:, val_demo_example_idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process_demo_rollouts(demo_rollouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(size):\n",
    "  idxes = random.sample(train_demo_example_idxes, size)\n",
    "  demo_batch = demo_obs[:, idxes], demo_actions[:, idxes]\n",
    "  return demo_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "iterations = 100000\n",
    "learning_rate = 1e-3\n",
    "batch_size = 512 // n_train_tasks\n",
    "sq_td_err_penalty = 1e0\n",
    "\n",
    "q_n_layers = 1\n",
    "q_layer_size = 32\n",
    "q_activation = tf.nn.relu\n",
    "q_output_activation = None\n",
    "\n",
    "constraint_sampling_freq = 100000\n",
    "constraint_batch_size = batch_size\n",
    "n_constraint_rollouts_per_env = 500\n",
    "\n",
    "val_update_freq = 100\n",
    "n_val_eval_rollouts = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_scope = str(uuid.uuid4())\n",
    "q_scope = str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_feats])\n",
    "demo_act_t_ph = tf.placeholder(tf.int32, [n_train_tasks, None])\n",
    "demo_batch_size_ph = tf.placeholder(tf.int32)\n",
    "\n",
    "constraint_obs_t_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_obs_feats])\n",
    "constraint_act_t_ph = tf.placeholder(tf.int32, [n_train_tasks, None])\n",
    "constraint_act_t_feats_ph = tf.placeholder(tf.float32, [n_train_tasks, None, n_act_feats])\n",
    "constraint_batch_size_ph = tf.placeholder(tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo_batch_idxes = tf.reshape(\n",
    "  tf.range(0, demo_batch_size_ph, 1), \n",
    "  [demo_batch_size_ph, 1])\n",
    "\n",
    "extract_task = lambda x, i: tf.squeeze(tf.gather(x, tf.convert_to_tensor(\n",
    "  [i], dtype=tf.int32)), axis=[0]) \n",
    "\n",
    "demo_q_t = tf.stack([tf.gather_nd(\n",
    "  build_mlp(\n",
    "    extract_task(demo_obs_t_ph, train_task_idx),\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation\n",
    "  ), \n",
    "  tf.concat([\n",
    "    demo_batch_idxes, \n",
    "    tf.expand_dims(extract_task(demo_act_t_ph, train_task_idx), 1)], axis=1)\n",
    ") for train_task_idx in range(n_train_tasks)], axis=0)\n",
    "\n",
    "demo_v_t = tf.reduce_logsumexp(\n",
    "  tf.stack([build_mlp(\n",
    "    extract_task(demo_obs_t_ph, train_task_idx),\n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation,\n",
    "    reuse=True\n",
    "  ) for train_task_idx in range(n_train_tasks)], axis=0),\n",
    "  axis=2)\n",
    "\n",
    "act_log_likelihoods = demo_q_t - demo_v_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neg_avg_log_likelihood = -tf.reduce_mean(act_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constraint_act_t_feats_reshaped = tf.reshape(\n",
    "  constraint_act_t_feats_ph, [n_train_tasks*constraint_batch_size_ph, n_act_feats])\n",
    "\n",
    "constraint_obs_t_reshaped = tf.reshape(\n",
    "  constraint_obs_t_ph, [n_train_tasks*constraint_batch_size_ph, n_obs_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert n_obs_feats == 4\n",
    "assert n_act_feats == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_dyn_A_fixed = np.zeros((n_obs_feats, 2))\n",
    "int_dyn_A_fixed[[0, 1], [0, 1]] = 1\n",
    "\n",
    "int_dyn_A_top = np.zeros((2, 2))\n",
    "int_dyn_A_top[[0, 1], [0, 1]] = 1\n",
    "int_dyn_A_top = tf.convert_to_tensor(int_dyn_A_top, tf.float32)\n",
    "int_dyn_A_top *= 1 / (1 + tf.exp(-tf.get_variable(\n",
    "  im_scope+'-A-top', [1], \n",
    "  initializer=tf.random_normal_initializer)))\n",
    "\n",
    "int_dyn_A_bot = np.zeros((2, 2))\n",
    "int_dyn_A_bot[[0, 1], [0, 1]] = 1\n",
    "int_dyn_A_bot = tf.convert_to_tensor(int_dyn_A_bot, tf.float32)\n",
    "int_dyn_A_bot *= 1 / (1 + tf.exp(-tf.get_variable(\n",
    "  im_scope+'-A-bot', [1],\n",
    "  initializer=tf.random_normal_initializer)))\n",
    "\n",
    "int_dyn_A = tf.concat([\n",
    "  tf.convert_to_tensor(int_dyn_A_fixed, tf.float32), \n",
    "  tf.concat([int_dyn_A_top, int_dyn_A_bot], axis=0)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_dyn_B_vel = np.zeros((n_obs_feats, n_act_feats))\n",
    "int_dyn_B_vel[[0, 1], [0, 1]] = 1\n",
    "int_dyn_B_vel = tf.convert_to_tensor(int_dyn_B_vel, tf.float32)\n",
    "\n",
    "int_dyn_B_acc = np.zeros((n_obs_feats, n_act_feats))\n",
    "int_dyn_B_acc[[2, 3], [0, 1]] = 1\n",
    "int_dyn_B_acc = tf.convert_to_tensor(int_dyn_B_acc, tf.float32)\n",
    "\n",
    "int_dyn_B_switch = 1 / (1 + tf.exp(-tf.get_variable(\n",
    "  im_scope+'-B', [1], \n",
    "  initializer=tf.random_normal_initializer)))\n",
    "\n",
    "int_dyn_B = int_dyn_B_switch * int_dyn_B_vel + (1 - int_dyn_B_switch) * int_dyn_B_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_dyn_A_mask = np.zeros((n_obs_feats, n_obs_feats))\n",
    "mask_idxes = [[0, 0], [0, 2], [1, 1], [1, 3], [2, 2], [3, 3]]\n",
    "for x, y in mask_idxes:\n",
    "  int_dyn_A_mask[x, y] = 1\n",
    "int_dyn_A *= int_dyn_A_mask\n",
    "\n",
    "int_dyn_B_mask = np.zeros((n_obs_feats, n_act_feats))\n",
    "mask_idxes = [[0, 0], [1, 1], [2, 0], [3, 1]]\n",
    "for x, y in mask_idxes:\n",
    "  int_dyn_B_mask[x, y] = 1\n",
    "int_dyn_B *= int_dyn_B_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint_obs_tp1 = tf.reshape(\n",
    "  tf.transpose(tf.matmul(int_dyn_A, tf.transpose(\n",
    "  constraint_obs_t_reshaped)) + tf.matmul(int_dyn_B, tf.transpose(\n",
    "  constraint_act_t_feats_reshaped))), \n",
    "  [n_train_tasks, constraint_batch_size_ph, n_obs_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_tp1 = tf.stack([build_mlp(\n",
    "  extract_task(constraint_obs_tp1, train_task_idx),\n",
    "  n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "  n_layers=q_n_layers, size=q_layer_size,\n",
    "  activation=q_activation, output_activation=q_output_activation, \n",
    "  reuse=True) for train_task_idx in range(n_train_tasks)], axis=0)\n",
    "v_tp1 = tf.reduce_logsumexp(q_tp1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rew_ts = []\n",
    "for train_task_idx in range(n_train_tasks):\n",
    "  goal_x = tf.convert_to_tensor(train_goals[train_task_idx, 0], dtype=tf.float32)\n",
    "  goal_y = tf.convert_to_tensor(train_goals[train_task_idx, 1], dtype=tf.float32)\n",
    "  \n",
    "  constraint_obs_tp1_of_task = extract_task(constraint_obs_tp1, train_task_idx)\n",
    "  constraint_obs_t_of_task = extract_task(constraint_obs_t_ph, train_task_idx)\n",
    "\n",
    "  pos_x_tp1 = tf.gather(constraint_obs_tp1_of_task, tf.convert_to_tensor(\n",
    "    [0], dtype=tf.int32), axis=1)\n",
    "  \n",
    "  pos_y_tp1 = tf.gather(constraint_obs_tp1_of_task, tf.convert_to_tensor(\n",
    "    [1], dtype=tf.int32), axis=1)\n",
    "  \n",
    "  pos_x_t = tf.gather(constraint_obs_t_of_task, tf.convert_to_tensor(\n",
    "    [0], dtype=tf.int32), axis=1)\n",
    "  \n",
    "  pos_y_t = tf.gather(constraint_obs_t_of_task, tf.convert_to_tensor(\n",
    "    [1], dtype=tf.int32), axis=1)\n",
    "\n",
    "  dist_to_goal_t = tf.sqrt((pos_x_t-goal_x)**2+(pos_y_t-goal_y)**2)\n",
    "  dist_to_goal_tp1 = tf.sqrt((pos_x_tp1-goal_x)**2+(pos_y_tp1-goal_y)**2)\n",
    "\n",
    "  crashed_t = tf.logical_or(tf.logical_or(tf.logical_or(\n",
    "    pos_x_tp1 < 0, pos_y_tp1 < 0), pos_x_tp1 >= 1), pos_y_tp1 >= 1)\n",
    "  succed_t = tf.logical_and(\n",
    "    tf.abs(pos_x_tp1-goal_x) <= goal_dist_thresh, \n",
    "    tf.abs(pos_y_tp1-goal_y) <= goal_dist_thresh)\n",
    "\n",
    "  rew_t = -gamma*dist_to_goal_tp1 + dist_to_goal_t\n",
    "  rew_t += crash_rew_penalty * tf.cast(crashed_t, tf.float32)\n",
    "  rew_t += succ_rew_bonus * tf.cast(tf.logical_and(tf.logical_not(crashed_t), succed_t), tf.float32)\n",
    "  rew_t = tf.squeeze(rew_t)\n",
    "  \n",
    "  rew_ts.append(rew_t)\n",
    "rew_t = tf.stack(rew_ts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_t = rew_t + gamma * v_tp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constraint_batch_idxes = tf.reshape(\n",
    "  tf.range(0, constraint_batch_size_ph, 1), \n",
    "  [constraint_batch_size_ph, 1])\n",
    "\n",
    "q_t = tf.stack([tf.gather_nd(\n",
    "  build_mlp(\n",
    "    extract_task(constraint_obs_t_ph, train_task_idx), \n",
    "    n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "    n_layers=q_n_layers, size=q_layer_size,\n",
    "    activation=q_activation, output_activation=q_output_activation, \n",
    "    reuse=True\n",
    "  ), \n",
    "  tf.concat([\n",
    "    constraint_batch_idxes, \n",
    "    tf.expand_dims(extract_task(constraint_act_t_ph, train_task_idx), 1)], axis=1)\n",
    ") for train_task_idx in range(n_train_tasks)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td_err = q_t - target_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sq_td_err = tf.reduce_mean(td_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = neg_avg_log_likelihood + sq_td_err_penalty * sq_td_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "update_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samp_obs_t_ph = tf.placeholder(tf.float32, [None, n_obs_feats])\n",
    "samp_act_t_feats_ph = tf.placeholder(tf.float32, [None, n_act_feats])\n",
    "\n",
    "samp_q_t = [build_mlp(\n",
    "  samp_obs_t_ph, \n",
    "  n_act_dim, q_scope+'-'+str(train_task_idx), \n",
    "  n_layers=q_n_layers, size=q_layer_size,\n",
    "  activation=q_activation, output_activation=q_output_activation, \n",
    "  reuse=True\n",
    ") for train_task_idx in range(n_train_tasks)]\n",
    "\n",
    "samp_obs_tp1 = tf.transpose(tf.matmul(int_dyn_A, tf.transpose(\n",
    "  samp_obs_t_ph)) + tf.matmul(int_dyn_B, tf.transpose(\n",
    "  samp_act_t_feats_ph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_val_assisted_env():\n",
    "  test_goal = np.random.random(2)\n",
    "  test_reward_func = make_reward_func(test_goal)\n",
    "  test_aristotle_pilot_policy = make_aristotle_pilot_policy(test_goal, denoise=True)\n",
    "  env = PointMassNav(using_inertia=True, reward_func=test_reward_func, goal=test_goal)\n",
    "  return test_aristotle_pilot_policy, env\n",
    "\n",
    "def compute_assisted_perf(): \n",
    "  assisted_rollouts = [[] for _ in range(n_val_eval_rollouts)]\n",
    "  test_aristotle_pilot_policies, envs = zip(*[make_val_assisted_env(\n",
    "    ) for _ in range(n_val_eval_rollouts)])\n",
    "  obses = np.array([env.reset() for env in envs])\n",
    "  dones = [False for _ in envs]\n",
    "  prev_obses = obses\n",
    "  for step_idx in range(max_ep_len+1):\n",
    "    not_done_idxes = [i for i, done in enumerate(dones) if not done]\n",
    "    if not_done_idxes == []:\n",
    "      break\n",
    "    act_feats = np.array([featurize_act(\n",
    "      test_aristotle_pilot_policies[i](obses[i])) for i in not_done_idxes])\n",
    "    obs_feats = np.array(\n",
    "      [featurize_obs(obses[i]) for i in not_done_idxes])\n",
    "    feed_dict = {\n",
    "      samp_obs_t_ph: obs_feats,\n",
    "      samp_act_t_feats_ph: act_feats\n",
    "    }\n",
    "    intended_obses = sess.run(samp_obs_tp1, feed_dict=feed_dict)\n",
    "\n",
    "    intended_actions = [inverse_real_dyn(\n",
    "      obs_feats[i], intended_obses[i]) for i in range(len(not_done_idxes))]\n",
    "\n",
    "    for i, env_idx in enumerate(not_done_idxes):\n",
    "      action = intended_actions[i]\n",
    "      obs, r, done, info = envs[env_idx].step(action)\n",
    "      obses[env_idx] = obs\n",
    "      dones[env_idx] = done\n",
    "      assisted_rollouts[env_idx].append((prev_obses[env_idx], None, r, obs, float(done), None))\n",
    "    prev_obses = copy(obses)\n",
    "\n",
    "  assisted_rew = np.mean([sum(x[2] for x in r) for r in assisted_rollouts])\n",
    "  assisted_succ = np.mean([1 if is_succ(r) else 0 for r in assisted_rollouts])\n",
    "  assisted_crash = np.mean([1 if is_crash(r) else 0 for r in assisted_rollouts])\n",
    "  assisted_perf = {\n",
    "    'assisted_rew': assisted_rew,\n",
    "    'assisted_succ': assisted_succ,\n",
    "    'assisted_crash': assisted_crash\n",
    "  }\n",
    "  return assisted_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_dyn_A_true = np.zeros((n_obs_feats, n_obs_feats))\n",
    "int_dyn_A_true[[0, 0, 1, 1], [0, 2, 1, 3]] = 1\n",
    "int_dyn_B_true = np.zeros((n_obs_feats, 2))\n",
    "int_dyn_B_true[[0, 1], [0, 1]] = 1\n",
    "def compute_int_dyn_err():\n",
    "  int_dyn_A_eval = sess.run(int_dyn_A)\n",
    "  int_dyn_B_eval = sess.run(int_dyn_B)\n",
    "  return {'int_dyn_err': \n",
    "          np.linalg.norm(int_dyn_A_true - int_dyn_A_eval) + np.linalg.norm(\n",
    "            int_dyn_B_true - int_dyn_B_eval)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_constraints(_):\n",
    "  constraint_rollouts = [[] for _ in range(n_train_tasks)]\n",
    "\n",
    "  for train_task_idx in range(n_train_tasks):\n",
    "    rollouts = [[] for _ in range(n_constraint_rollouts_per_env)]\n",
    "    envs = [copy(train_newton_envs[train_task_idx]) for _ in range(n_constraint_rollouts_per_env)]\n",
    "    obses = np.array([env.reset() for env in envs])\n",
    "    dones = [False for _ in envs]\n",
    "    prev_obses = obses\n",
    "    for step_idx in range(max_ep_len+1):\n",
    "      not_done_idxes = [i for i, done in enumerate(dones) if not done]\n",
    "      batch_size = len(not_done_idxes)\n",
    "      if batch_size == 0:\n",
    "        break\n",
    "      actions = np.random.choice(n_act_dim, batch_size)\n",
    "      for i, env_idx in enumerate(not_done_idxes):\n",
    "        env = envs[env_idx]\n",
    "        action = actions[i]\n",
    "        obs, r, done, info = env.step(action)\n",
    "        obses[env_idx] = obs\n",
    "        dones[env_idx] = done\n",
    "        rollouts[env_idx].append((prev_obses[env_idx], action))\n",
    "      prev_obses = copy(obses)\n",
    "    constraint_rollouts[train_task_idx].extend([r for r in rollouts if r != []])\n",
    "\n",
    "  size = min(sum(len(r) for r in rollouts) for rollouts in constraint_rollouts)\n",
    "  \n",
    "  global train_constraint_example_idxes\n",
    "  global val_constraint_batch\n",
    "  global constraint_obs_t\n",
    "  global constraint_act_t\n",
    "  global constraint_act_t_feats\n",
    "    \n",
    "  constraint_obs_t = np.zeros((n_train_tasks, size, n_obs_feats))\n",
    "  constraint_act_t = np.zeros((n_train_tasks, size))\n",
    "  constraint_act_t_feats = np.zeros((n_train_tasks, size, n_act_feats))\n",
    "  \n",
    "  for train_task_idx in range(n_train_tasks):\n",
    "    unfeat_obses, actions = list(zip(*sum(\n",
    "      constraint_rollouts[train_task_idx], [])))\n",
    "    obses = [featurize_obs(s) for s in unfeat_obses]\n",
    "    act_feats = [featurize_act(a) for a in actions]\n",
    "    idxes = random.sample(list(range(len(obses))), size)\n",
    "    constraint_obs_t[train_task_idx, :, :] = np.array(obses)[idxes, :]\n",
    "    constraint_act_t[train_task_idx, :] = np.array(actions)[idxes]\n",
    "    constraint_act_t_feats[train_task_idx, :, :] = np.array(act_feats)[idxes, :]\n",
    "  \n",
    "  constraint_example_idxes = list(range(size))\n",
    "  random.shuffle(constraint_example_idxes)\n",
    "  n_train_constraint_examples = int(0.9 * size)\n",
    "  \n",
    "  train_constraint_example_idxes = constraint_example_idxes[:n_train_constraint_examples]\n",
    "  val_constraint_example_idxes = constraint_example_idxes[n_train_constraint_examples:]\n",
    "  val_constraint_batch = constraint_obs_t[:, val_constraint_example_idxes], constraint_act_t[:, val_constraint_example_idxes], constraint_act_t_feats[:, val_constraint_example_idxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_constraint_batch(size):\n",
    "  global n_iters_since_prev_constraint_sample\n",
    "  if n_iters_since_prev_constraint_sample % constraint_sampling_freq == 0:\n",
    "    sample_constraints(size)\n",
    "    n_iters_since_prev_constraint_sample = 0\n",
    "  n_iters_since_prev_constraint_sample += 1\n",
    "\n",
    "  idxes = random.sample(train_constraint_example_idxes, size)\n",
    "  constraint_batch = constraint_obs_t[:, idxes], constraint_act_t[:, idxes], constraint_act_t_feats[:, idxes]\n",
    "  return constraint_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_constraint_example_idxes = None\n",
    "val_constraint_batch = None\n",
    "constraint_obs_t = None\n",
    "constraint_act_t = None\n",
    "constraint_act_t_feats = None\n",
    "n_iters_since_prev_constraint_sample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_iters = iterations * demo_obs.shape[1] // batch_size\n",
    "train_logs = {\n",
    "  'loss_evals': [],\n",
    "  'nll_evals': [],\n",
    "  'ste_evals': [],\n",
    "  'val_loss_evals': [],\n",
    "  'val_nll_evals': [],\n",
    "  'val_ste_evals': [],\n",
    "  'assisted_rew_evals': [],\n",
    "  'assisted_succ_evals': [],\n",
    "  'assisted_crash_evals': [],\n",
    "  'int_dyn_err_evals': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_batch_loss(demo_batch, constraint_batch, step=False, t=None):\n",
    "  demo_batch_obs_t, demo_batch_act_t = demo_batch\n",
    "  constraint_batch_obs_t, constraint_batch_act_t, constraint_batch_act_t_feats = constraint_batch\n",
    "    \n",
    "  feed_dict = {\n",
    "    demo_obs_t_ph: demo_batch_obs_t,\n",
    "    demo_act_t_ph: demo_batch_act_t,\n",
    "    demo_batch_size_ph: demo_batch_obs_t.shape[1],\n",
    "    constraint_obs_t_ph: constraint_batch_obs_t,\n",
    "    constraint_act_t_ph: constraint_batch_act_t,\n",
    "    constraint_act_t_feats_ph: constraint_batch_act_t_feats,\n",
    "    constraint_batch_size_ph: constraint_batch_obs_t.shape[1],\n",
    "  }\n",
    "  \n",
    "  [loss_eval, neg_avg_log_likelihood_eval, sq_td_err_eval] = sess.run(\n",
    "    [loss, neg_avg_log_likelihood, sq_td_err], feed_dict=feed_dict)\n",
    "  \n",
    "  if step:\n",
    "    sess.run(update_op, feed_dict=feed_dict)\n",
    "  \n",
    "  d = {\n",
    "    'loss': loss_eval,\n",
    "    'nll': neg_avg_log_likelihood_eval,\n",
    "    'ste': sq_td_err_eval\n",
    "  }\n",
    "  if not step:\n",
    "    d.update(compute_int_dyn_err())\n",
    "    d.update(compute_assisted_perf())\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_log = None\n",
    "while len(train_logs['loss_evals']) < n_iters:\n",
    "  demo_batch = sample_batch(batch_size)\n",
    "  constraint_batch = sample_constraint_batch(constraint_batch_size)\n",
    "  \n",
    "  t = len(train_logs['loss_evals'])\n",
    "  train_log = compute_batch_loss(demo_batch, constraint_batch, step=True, t=t)\n",
    "  if val_log is None or len(train_logs['loss_evals']) % val_update_freq == 0:\n",
    "    val_log = compute_batch_loss(val_demo_batch, val_constraint_batch, step=False, t=t)\n",
    "  \n",
    "  print('%d %d %f %f %f %f %f %f %f' % (\n",
    "    t, n_iters, train_log['loss'],\n",
    "    train_log['nll'], train_log['ste'], val_log['loss'],\n",
    "    val_log['nll'], val_log['ste'], val_log['int_dyn_err'])\n",
    "  )\n",
    "  \n",
    "  for k, v in train_log.items():\n",
    "    train_logs['%s_evals' % k].append(v)\n",
    "  for k, v in val_log.items():\n",
    "    train_logs['%s%s_evals' % ('val_' if k in ['loss', 'nll', 'ste'] else '', k)].append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in ['val_nll_evals', 'val_ste_evals']:\n",
    "  plt.xlabel('Iterations')\n",
    "  plt.ylabel(k.split('_')[1])\n",
    "  plt.plot(train_logs[k])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Reward')\n",
    "plt.axhline(y=np.mean(ideal_rew), linestyle='--', color='teal', label='Optimal')\n",
    "plt.axhline(y=np.mean(unassisted_rew), linestyle=':', color='gray', label='Unassisted')\n",
    "plt.plot(train_logs['assisted_rew_evals'], color='orange', label='Assisted')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Success Rate')\n",
    "plt.axhline(y=np.mean(ideal_succ), linestyle='--', color='teal', label='Optimal')\n",
    "plt.axhline(y=np.mean(unassisted_succ), linestyle=':', color='gray', label='Unassisted')\n",
    "plt.plot(train_logs['assisted_succ_evals'], color='orange', label='Assisted')\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Crash Rate')\n",
    "plt.axhline(y=np.mean(ideal_crash), linestyle='--', color='teal', label='Optimal')\n",
    "plt.axhline(y=np.mean(unassisted_crash), linestyle=':', color='gray', label='Unassisted')\n",
    "plt.plot(train_logs['assisted_crash_evals'], color='orange', label='Assisted')\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('L2 Error')\n",
    "plt.plot(train_logs['int_dyn_err_evals'], color='orange')\n",
    "plt.ylim([-0.05, None])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run(int_dyn_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sess.run(int_dyn_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat with ten different random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master_train_logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "  train_constraint_example_idxes = None\n",
    "  val_constraint_batch = None\n",
    "  constraint_obs_t = None\n",
    "  constraint_act_t = None\n",
    "  constraint_act_t_feats = None\n",
    "  n_iters_since_prev_constraint_sample = 0\n",
    "  tf.global_variables_initializer().run(session=sess)\n",
    "  \n",
    "  n_iters = 20000\n",
    "  train_logs = {\n",
    "    'loss_evals': [],\n",
    "    'nll_evals': [],\n",
    "    'ste_evals': [],\n",
    "    'val_loss_evals': [],\n",
    "    'val_nll_evals': [],\n",
    "    'val_ste_evals': [],\n",
    "    'assisted_rew_evals': [],\n",
    "    'assisted_succ_evals': [],\n",
    "    'assisted_crash_evals': [],\n",
    "    'int_dyn_err_evals'\n",
    "  }\n",
    "  \n",
    "  val_log = None\n",
    "  while len(train_logs['loss_evals']) < n_iters:\n",
    "    demo_batch = sample_batch(batch_size)\n",
    "    constraint_batch = sample_constraint_batch(constraint_batch_size)\n",
    "\n",
    "    t = len(train_logs['loss_evals'])\n",
    "    train_log = compute_batch_loss(demo_batch, constraint_batch, step=True, t=t)\n",
    "    if val_log is None or t % val_update_freq == 0:\n",
    "      val_log = compute_batch_loss(val_demo_batch, val_constraint_batch, step=False, t=t)\n",
    "\n",
    "    if t % 1000 == 0:\n",
    "      print('%d %d %f %f %f %f %f %f %f' % (\n",
    "        t, n_iters, train_log['loss'],\n",
    "        train_log['nll'], train_log['ste'], val_log['loss'],\n",
    "        val_log['nll'], val_log['ste'], val_log['int_dyn_err'])\n",
    "      )\n",
    "\n",
    "    for k, v in train_log.items():\n",
    "      train_logs['%s_evals' % k].append(v)\n",
    "    for k, v in val_log.items():\n",
    "      train_logs['%s%s_evals' % ('val_' if k in ['loss', 'nll', 'ste'] else '', k)].append(v)\n",
    "      \n",
    "  master_train_logs.append(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'master_train_logs.pkl'), 'wb') as f:\n",
    "  pickle.dump(master_train_logs, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "internal2real dynamics transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newton_env = train_newton_envs[0].unwrapped\n",
    "def inverse_real_dyn(state, next_state, vel_thresh=accel):#=1e-9):#\n",
    "  pos = state[:2]\n",
    "  vel = state[2:]\n",
    "  next_states = np.array([newton_env._obs_of_pos_vel(*newton_env._next_pos_vel(pos, vel, a)) for a in range(n_act_dim)])\n",
    "  if (np.abs(state[2:]) <= vel_thresh).all():\n",
    "    dists = np.linalg.norm(next_state[:2] - next_states[:, :2], axis=1)\n",
    "  else:\n",
    "    dists = np.linalg.norm(next_state[2:] - next_states[:, 2:], axis=1)\n",
    "  return np.argmax(-dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dyn_transfer(state, action):\n",
    "  act_feats = np.array([featurize_act(action)])\n",
    "  obs_feats = np.array([featurize_obs(state)])\n",
    "  feed_dict = {\n",
    "    samp_obs_t_ph: obs_feats,\n",
    "    samp_act_t_feats_ph: act_feats\n",
    "  }\n",
    "  next_state = sess.run(samp_obs_tp1, feed_dict=feed_dict)[0]\n",
    "  return inverse_real_dyn(state, next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_assisted_env(goal=None):\n",
    "  test_goal = np.random.random(2) if goal is None else goal\n",
    "  test_reward_func = make_reward_func(test_goal)\n",
    "  test_aristotle_pilot_policy = make_aristotle_pilot_policy(test_goal, denoise=True)\n",
    "  env = PointMassNav(reward_func=test_reward_func, goal=test_goal, using_inertia=True)\n",
    "  env.unwrapped._step_orig = env.unwrapped._step\n",
    "  def _step(self, action):\n",
    "    transferred_act = dyn_transfer(self.curr_obs, action)\n",
    "    obs, r, done, info = self._step_orig(transferred_act)\n",
    "    return obs, r, done, info\n",
    "  env.unwrapped._step = types.MethodType(_step, env.unwrapped)\n",
    "  return test_aristotle_pilot_policy, env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_env_without_dyn_transfer(using_inertia=True, goal=None):\n",
    "  test_goal = np.random.random(2) if goal is None else goal\n",
    "  test_reward_func = make_reward_func(test_goal)\n",
    "  test_aristotle_pilot_policy = make_aristotle_pilot_policy(test_goal, denoise=True)\n",
    "  unassisted_env = PointMassNav(using_inertia=using_inertia, reward_func=test_reward_func, goal=test_goal)\n",
    "  return test_aristotle_pilot_policy, unassisted_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_unassisted_env = lambda: make_env_without_dyn_transfer(using_inertia=True)\n",
    "make_ideal_env = lambda: make_env_without_dyn_transfer(using_inertia=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_eval_rollouts = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assisted_rollouts = [run_ep(*make_assisted_env(), render=False) for _ in range(n_eval_rollouts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_assisted_rollouts.pkl'), 'wb') as f:\n",
    "  pickle.dump(assisted_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_assisted_rollouts.pkl'), 'rb') as f:\n",
    "  assisted_rollouts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unassisted_rollouts = [run_ep(*make_unassisted_env(), render=False) for _ in range(n_eval_rollouts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_unassisted_rollouts.pkl'), 'wb') as f:\n",
    "  pickle.dump(unassisted_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_unassisted_rollouts.pkl'), 'rb') as f:\n",
    "  unassisted_rollouts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ideal_rollouts = [run_ep(*make_ideal_env(), render=False) for _ in range(n_eval_rollouts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_ideal_rollouts.pkl'), 'wb') as f:\n",
    "  pickle.dump(ideal_rollouts, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'aristotle_pilot_policy_ideal_rollouts.pkl'), 'rb') as f:\n",
    "  ideal_rollouts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unassisted_rew = [sum(x[2] for x in r) for r in unassisted_rollouts]\n",
    "ideal_rew = [sum(x[2] for x in r) for r in ideal_rollouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assisted_rew = [sum(x[2] for x in r) for r in assisted_rollouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(unassisted_rew), np.mean(ideal_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(assisted_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unassisted_succ = [1 if is_succ(r) else 0 for r in unassisted_rollouts]\n",
    "ideal_succ = [1 if is_succ(r) else 0 for r in ideal_rollouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assisted_succ = [1 if is_succ(r) else 0 for r in assisted_rollouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(unassisted_succ), np.mean(ideal_succ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(assisted_succ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unassisted_crash = [1 if is_crash(r) else 0 for r in unassisted_rollouts]\n",
    "ideal_crash = [1 if is_crash(r) else 0 for r in ideal_rollouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assisted_crash = [1 if is_crash(r) else 0 for r in assisted_rollouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(unassisted_crash), np.mean(ideal_crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(assisted_crash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viz trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_trajectories(\n",
    "  rollouts, goal, title, file_name=None):\n",
    "  plt.title(title)\n",
    "\n",
    "  for rollout in rollouts:\n",
    "    trajectory = [x[0] for x in rollout] + [rollout[-1][3]]\n",
    "    x, y, vx, vy = list(zip(*trajectory))\n",
    "    if is_succ(rollout):\n",
    "      cmap = mpl.cm.YlGn\n",
    "    elif is_crash(rollout):\n",
    "      cmap = mpl.cm.YlOrRd\n",
    "    else:\n",
    "      cmap = mpl.cm.gray\n",
    "    plt.scatter(x, y, c=range(len(x)), cmap=cmap, alpha=0.75, linewidth=0)\n",
    "    plt.scatter(\n",
    "      [goal[0]], [goal[1]], marker='*', color='yellow', \n",
    "      edgecolor='black', linewidth=1, s=300, alpha=0.5)\n",
    "    \n",
    "  plt.xlim([-0.05, 1.05])\n",
    "  plt.ylim([-0.05, 1.05])\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.axis('off')\n",
    "  if file_name is not None:\n",
    "    plt.savefig(os.path.join(data_dir, file_name), bbox_inches='tight')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_viz_rollouts = 100\n",
    "center_goal = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_aristotle_pilot_policy, assisted_env = make_assisted_env(goal=center_goal)\n",
    "assisted_rollouts = [run_ep(\n",
    "  test_aristotle_pilot_policy, assisted_env, render=False) for _ in range(n_viz_rollouts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_aristotle_pilot_policy, unassisted_env = make_env_without_dyn_transfer(\n",
    "  using_inertia=True, goal=center_goal)\n",
    "unassisted_rollouts = [run_ep(\n",
    "  test_aristotle_pilot_policy, unassisted_env, render=False) for _ in range(n_viz_rollouts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unassisted_rollouts_sample = random.sample(unassisted_rollouts, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mpl.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_trajectories(\n",
    "  unassisted_rollouts_sample, center_goal, 'Unassisted', 'unassisted-traj.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assisted_rollouts_sample = random.sample(assisted_rollouts, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_trajectories(assisted_rollouts_sample, center_goal, 'Assisted', 'assisted-traj.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_ep(test_aristotle_pilot_policy, assisted_env, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assisted_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viz master logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, 'master_train_logs.pkl'), 'rb') as f:\n",
    "  master_train_logs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def err_vs_iter_of_logs(master_train_logs):\n",
    "  n_reps = len(master_train_logs)\n",
    "  max_iter = max(len(\n",
    "    train_logs['int_dyn_err_evals']) for train_logs in master_train_logs)\n",
    "  R = np.zeros((n_reps, max_iter))\n",
    "  R[:, :] = np.nan\n",
    "  for i, train_logs in enumerate(master_train_logs):\n",
    "    errs = train_logs['int_dyn_err_evals']\n",
    "    R[i, :len(errs)] = errs\n",
    "  return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth_win = 100\n",
    "def moving_avg(d, n=smooth_win):\n",
    "  s = np.concatenate((np.zeros(1), np.cumsum(d).astype(float)))\n",
    "  return (s[n:] - s[:-n]) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traj_col_means = lambda x: np.nanmean(x, axis=0)\n",
    "traj_col_stderrs = lambda x: np.nanstd(x, axis=0) / np.sqrt(\n",
    "  np.count_nonzero(~np.isnan(x), axis=0))\n",
    "r_mins = lambda x: traj_col_means(x) - traj_col_stderrs(x)\n",
    "r_maxs = lambda x: traj_col_means(x) + traj_col_stderrs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = err_vs_iter_of_logs(master_train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_fill(R, color, label):\n",
    "  x = range(R.shape[1] - (smooth_win - 1))\n",
    "  y1 = moving_avg(r_mins(R), n=smooth_win)\n",
    "  y2 = moving_avg(r_maxs(R), n=smooth_win)\n",
    "  plt.fill_between(\n",
    "    x, y1, y2, where=y2 >= y1, interpolate=True, facecolor=color, alpha=0.5)\n",
    "  plt.plot(moving_avg(traj_col_means(R), n=smooth_win), color=color, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Number of Gradient Steps')\n",
    "plt.ylabel('Internal Dynamics L2 Error')\n",
    "plt.title('2D Continuous-State Navigation')\n",
    "\n",
    "plot_fill(R, 'orange', 'Our Method')\n",
    "\n",
    "plt.axhline(y=0.25, linestyle='--', color='gray', label='Random')\n",
    "\n",
    "plt.ylim([-0.05, None])\n",
    "plt.xlim([0, 10000])\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(os.path.join(data_dir, 'err-vs-iter.pdf'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
